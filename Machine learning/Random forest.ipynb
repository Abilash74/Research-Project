{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a461094-def4-4b99-a713-70bf7f7d6839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1/10...\n",
      "4/4 [==============================] - 0s 34ms/step\n",
      "Processing Fold 2/10...\n",
      "4/4 [==============================] - 0s 35ms/step\n",
      "Processing Fold 3/10...\n",
      "4/4 [==============================] - 0s 35ms/step\n",
      "Processing Fold 4/10...\n",
      "4/4 [==============================] - 0s 35ms/step\n",
      "Processing Fold 5/10...\n",
      "4/4 [==============================] - 0s 35ms/step\n",
      "Processing Fold 6/10...\n",
      "4/4 [==============================] - 0s 35ms/step\n",
      "Processing Fold 7/10...\n",
      "4/4 [==============================] - 0s 35ms/step\n",
      "Processing Fold 8/10...\n",
      "4/4 [==============================] - 0s 35ms/step\n",
      "Processing Fold 9/10...\n",
      "4/4 [==============================] - 0s 35ms/step\n",
      "Processing Fold 10/10...\n",
      "4/4 [==============================] - 0s 35ms/step\n",
      "\n",
      "AUC (Synergistic vs. Rest):\n",
      "Hadamard: 0.5557\n",
      "L1-norm: 0.5559\n",
      "L2-norm: 0.5396\n",
      "Average: 0.5644\n",
      "Classification-based: 0.6282\n",
      "\n",
      "AUC (Antagonistic vs. Rest):\n",
      "Hadamard: 0.6198\n",
      "L1-norm: 0.5775\n",
      "L2-norm: 0.5946\n",
      "Average: 0.6253\n",
      "Classification-based: 0.5983\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import stellargraph as sg\n",
    "from stellargraph.data import UnsupervisedSampler\n",
    "from stellargraph.mapper import Attri2VecLinkGenerator, Attri2VecNodeGenerator\n",
    "from stellargraph.layer import Attri2Vec, link_classification\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "data_dir = \"data/\"  # working directory\n",
    "walk_length = 3\n",
    "number_of_walks = 3\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "layer_sizes = [16]\n",
    "kfold = 10\n",
    "\n",
    "# Read edge list\n",
    "edgelist = pd.read_csv(os.path.join(data_dir, \"pair_Sa\"),\n",
    "                       sep=\"\\t\", header=None, names=[\"source\", \"target\", \"label\", \"eo1\", \"eo2\"])\n",
    "\n",
    "# Read node list\n",
    "file_nodes = pd.read_csv(os.path.join(data_dir, \"pair_content_Sa\"), sep=\"\\t\")\n",
    "nodes = file_nodes.set_index('ID')\n",
    "feats = nodes.columns[:-1]  # Exclude label column\n",
    "\n",
    "# Create graph\n",
    "G_all_nx = nx.from_pandas_edgelist(edgelist, edge_attr=\"label\")\n",
    "nx.set_node_attributes(G_all_nx, \"label\", \"label\")\n",
    "G_all = sg.StellarGraph.from_networkx(G_all_nx, node_features=nodes[feats])\n",
    "\n",
    "# Store probabilities for each method\n",
    "synergy_probs = {\"Hadamard\": [], \"L1-norm\": [], \"L2-norm\": [], \"Average\": [], \"Classification-based\": []}\n",
    "antagonistic_probs = {\"Hadamard\": [], \"L1-norm\": [], \"L2-norm\": [], \"Average\": [], \"Classification-based\": []}\n",
    "lbl_p_synergistic, lbl_p_antagonistic = [], []\n",
    "\n",
    "# Train Attri2Vec model\n",
    "generator = Attri2VecNodeGenerator(G_all, batch_size)\n",
    "attri2vec = Attri2Vec(layer_sizes=layer_sizes, generator=generator, bias=False, normalize=None)\n",
    "x_inp, x_out = attri2vec.in_out_tensors()\n",
    "embedding_model = keras.Model(inputs=x_inp, outputs=x_out)\n",
    "\n",
    "for k in range(kfold):\n",
    "    print(f\"Processing Fold {k+1}/{kfold}...\")\n",
    "\n",
    "    # Read train and test interaction data\n",
    "    edge_t = pd.read_csv(os.path.join(data_dir, f\"{k+1}_t\"), sep=\"\\t\",\n",
    "                         header=None, names=[\"source\", \"target\", \"label\", \"eo1\", \"eo2\"])\n",
    "    edge_p = pd.read_csv(os.path.join(data_dir, f\"{k+1}_p\"), sep=\"\\t\",\n",
    "                         header=None, names=[\"source\", \"target\", \"label\", \"eo1\", \"eo2\"])\n",
    "\n",
    "    # Convert labels from [1,2,3] â†’ [0,1,2] for classification\n",
    "    edge_t[\"label\"] = edge_t[\"label\"] - 1\n",
    "    edge_p[\"label\"] = edge_p[\"label\"] - 1\n",
    "\n",
    "    # Generate embeddings\n",
    "    node_ids = nodes.index\n",
    "    node_gen = generator.flow(node_ids)\n",
    "    emb = embedding_model.predict(node_gen, workers=4, verbose=1)\n",
    "\n",
    "    # Function to extract edge features\n",
    "    def extract_features(edge_data):\n",
    "        feat_h, feat_L1, feat_L2, feat_av, feat_cmp_av = [], [], [], [], []\n",
    "        for i in range(len(edge_data)):\n",
    "            try:\n",
    "                n1 = np.where(nodes.index == edge_data[\"source\"][i])[0][0]\n",
    "                n2 = np.where(nodes.index == edge_data[\"target\"][i])[0][0]\n",
    "\n",
    "                feat_h.append(np.ravel(emb[n1] * emb[n2]))  # Hadamard\n",
    "                feat_L1.append(np.ravel(np.abs(emb[n1] - emb[n2])))  # L1-norm\n",
    "                feat_L2.append(np.ravel((emb[n1] - emb[n2]) ** 2))  # L2-norm\n",
    "                feat_av.append(np.ravel((emb[n1] + emb[n2]) / 2))  # Average\n",
    "                feat_cmp_av.append((nodes.loc[edge_data[\"source\"][i], feats] +\n",
    "                                    nodes.loc[edge_data[\"target\"][i], feats]) / 2)  # Classification-based\n",
    "            except IndexError:\n",
    "                print(f\"Skipping invalid edge: {edge_data.iloc[i].to_dict()}\")\n",
    "        \n",
    "        return np.array(feat_h), np.array(feat_L1), np.array(feat_L2), np.array(feat_av), np.array(feat_cmp_av)\n",
    "\n",
    "    # Extract features for training and testing\n",
    "    h_feat_t, L1_feat_t, L2_feat_t, av_feat_t, cmp_av_feat_t = extract_features(edge_t)\n",
    "    h_feat_p, L1_feat_p, L2_feat_p, av_feat_p, cmp_av_feat_p = extract_features(edge_p)\n",
    "\n",
    "    # Prepare labels\n",
    "    lbl_p = edge_p[\"label\"].values\n",
    "\n",
    "    # **Separate Labels for Two Models**\n",
    "    lbl_p_synergistic.extend((lbl_p == 1).astype(int))  # 1 for synergy, 0 for others\n",
    "    lbl_p_antagonistic.extend((lbl_p == 2).astype(int))  # 1 for antagonistic, 0 for others\n",
    "\n",
    "    # Function to train Random Forest for Binary Classification\n",
    "    def train_rf(train_X, train_y, test_X):\n",
    "        rf_model = RandomForestClassifier(n_estimators=100, random_state=seed)\n",
    "        rf_model.fit(train_X, train_y)\n",
    "        pred_proba = rf_model.predict_proba(test_X)[:, 1]  # Only positive class probability\n",
    "        return pred_proba\n",
    "\n",
    "    # **Train Separate Models for Each Feature Extraction Method**\n",
    "    synergy_probs[\"Hadamard\"].append(train_rf(h_feat_t, (edge_t[\"label\"] == 1).astype(int), h_feat_p))\n",
    "    synergy_probs[\"L1-norm\"].append(train_rf(L1_feat_t, (edge_t[\"label\"] == 1).astype(int), L1_feat_p))\n",
    "    synergy_probs[\"L2-norm\"].append(train_rf(L2_feat_t, (edge_t[\"label\"] == 1).astype(int), L2_feat_p))\n",
    "    synergy_probs[\"Average\"].append(train_rf(av_feat_t, (edge_t[\"label\"] == 1).astype(int), av_feat_p))\n",
    "    synergy_probs[\"Classification-based\"].append(train_rf(cmp_av_feat_t, (edge_t[\"label\"] == 1).astype(int), cmp_av_feat_p))\n",
    "\n",
    "    antagonistic_probs[\"Hadamard\"].append(train_rf(h_feat_t, (edge_t[\"label\"] == 2).astype(int), h_feat_p))\n",
    "    antagonistic_probs[\"L1-norm\"].append(train_rf(L1_feat_t, (edge_t[\"label\"] == 2).astype(int), L1_feat_p))\n",
    "    antagonistic_probs[\"L2-norm\"].append(train_rf(L2_feat_t, (edge_t[\"label\"] == 2).astype(int), L2_feat_p))\n",
    "    antagonistic_probs[\"Average\"].append(train_rf(av_feat_t, (edge_t[\"label\"] == 2).astype(int), av_feat_p))\n",
    "    antagonistic_probs[\"Classification-based\"].append(train_rf(cmp_av_feat_t, (edge_t[\"label\"] == 2).astype(int), cmp_av_feat_p))\n",
    "\n",
    "# Compute AUC scores separately\n",
    "print(\"\\nAUC (Synergistic vs. Rest):\")\n",
    "for method in synergy_probs:\n",
    "    print(f\"{method}: {roc_auc_score(lbl_p_synergistic, np.hstack(synergy_probs[method])):.4f}\")\n",
    "\n",
    "print(\"\\nAUC (Antagonistic vs. Rest):\")\n",
    "for method in antagonistic_probs:\n",
    "    print(f\"{method}: {roc_auc_score(lbl_p_antagonistic, np.hstack(antagonistic_probs[method])):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14956e7-0dda-4912-9781-5a93f9a99e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (stellargraph-env)",
   "language": "python",
   "name": "stellargraph-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
